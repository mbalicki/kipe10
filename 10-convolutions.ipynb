{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 29 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 29 days\n"
     ]
    }
   ],
   "source": [
    "% pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 780\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor.signal.downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "from scipy.ndimage.filters import convolve\n",
    "\n",
    "# note: this requires the starter code for the assignments!\n",
    "from common.plotting import plot_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST example\n",
    "\n",
    "We will now build a convolutional network for the MNIST data. We will use Theano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.mnist import MNIST\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "MNIST.default_transformers = ((ScaleAndShift, [2.0 / 255.0, -1], {\"which_sources\" : \"features\"}),\n",
    "                              (Cast, [np.float32], {\"which_sources\": \"features\"}))\n",
    "\n",
    "mnist_train = MNIST((\"train\",), subset = slice(None, 50000))\n",
    "# this stream will shuffle the MNIST set and return us batches of 100 examples\n",
    "mnist_train_stream = DataStream.default_stream(mnist_train,\n",
    "                                               iteration_scheme = ShuffledScheme(mnist_train.num_examples, 25))\n",
    "                                               \n",
    "mnist_validation = MNIST((\"train\",), subset = slice(50000, None))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "mnist_validation_stream = DataStream.default_stream(mnist_validation,\n",
    "                                                    iteration_scheme = SequentialScheme(mnist_validation.num_examples, 100))\n",
    "mnist_test = MNIST((\"test\",))\n",
    "mnist_test_stream = DataStream.default_stream(mnist_test,\n",
    "                                              iteration_scheme = SequentialScheme(mnist_test.num_examples, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (25, 1, 28, 28) containing float32\n",
      " - an array of size (25, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 1, 28, 28) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (mnist_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(mnist_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(mnist_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "\n",
    "class Constant():\n",
    "    '''Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    '''\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype = np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    '''Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    '''\n",
    "    def __init__(self, std = 1, mean = 0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size = shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    '''Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    '''\n",
    "    def __init__(self, mean = 0., width = None, std = None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1 / 12 * width ^ 2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size = shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# A theano variable is an entry to the cmputational graph\n",
    "# We will need to provide its value during function call\n",
    "# X is batch_size x num_channels x img_rows x img_columns\n",
    "X = theano.tensor.tensor4(\"X\")\n",
    "\n",
    "# Y is 1D, it lists the targets for all examples\n",
    "Y = theano.tensor.matrix(\"Y\", dtype = \"uint8\")\n",
    "\n",
    "#The tag values are useful during debugging the creation of Theano graphs\n",
    "\n",
    "X_test_value, Y_test_value = next(mnist_train_stream.get_epoch_iterator())\n",
    "\n",
    "# Unfortunately, test tags don't work with convolutions with newest Theano :(\n",
    "theano.config.compute_test_value = \"off\" # Enable the computation of test values\n",
    "\n",
    "\n",
    "X.tag.test_value = X_test_value[: 3]\n",
    "Y.tag.test_value = Y_test_value[: 3]\n",
    "\n",
    "print \"X shape: %s\" % (X.tag.test_value.shape,)\n",
    "\n",
    "# this list will hold all parameters of the network\n",
    "model_parameters = []\n",
    "\n",
    "# The first convolutional layer\n",
    "# The shape is: num_out_filters x num_in_filters x filter_height x filter_width\n",
    "num_filters_1 = 10 # we will apply that many convolution filters in the first layer\n",
    "CW1 = theano.shared(np.zeros((num_filters_1, 1, 5, 5), dtype = \"float32\"),\n",
    "                    name = \"CW1\")\n",
    "#please note - this is somewhat non-standard\n",
    "CW1.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "CB1 = theano.shared(np.zeros((num_filters_1,), dtype = \"float32\"),\n",
    "                    name = \"CB1\")\n",
    "CB1.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW1, CB1]\n",
    "\n",
    "after_C1 = theano.tensor.maximum(0.0,\n",
    "                                 theano.tensor.nnet.conv2d(X, CW1) + CB1.dimshuffle(\"x\", 0, \"x\", \"x\"))\n",
    "# print \"after_C1 shape: %s\" % (after_C1.tag.test_value.shape,)\n",
    "after_P1 = theano.tensor.signal.downsample.max_pool_2d(after_C1, (2, 2), ignore_border = True)\n",
    "# print \"after_P1 shape: %s\" % (after_P1.tag.test_value.shape,)\n",
    "\n",
    "\n",
    "num_filters_2 = 25 # we will compute ten convolution filters in the first layer\n",
    "CW2 = theano.shared(np.zeros((num_filters_2, num_filters_1, 5, 5), dtype = \"float32\"),\n",
    "                    name = \"CW2\")\n",
    "CW2.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "CB2 = theano.shared(np.zeros((num_filters_2,), dtype = \"float32\"),\n",
    "                    name = \"CB2\")\n",
    "CB2.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW2, CB2]\n",
    "\n",
    "after_C2 = theano.tensor.maximum(0.0,\n",
    "                                 theano.tensor.nnet.conv2d(after_P1, CW2) + CB2.dimshuffle(\"x\", 0, \"x\", \"x\"))\n",
    "# print \"after_C2 shape: %s\" % (after_C2.tag.test_value.shape,)\n",
    "after_P2 = theano.tensor.signal.downsample.max_pool_2d(after_C2, (2, 2), ignore_border = True)\n",
    "# print \"after_P2 shape: %s\" % (after_P2.tag.test_value.shape,)\n",
    "\n",
    "# Fully connected layers - we just flatten all filter maps\n",
    "num_fw3_hidden = 500\n",
    "FW3 = theano.shared(np.zeros((num_filters_2 * 4 * 4, num_fw3_hidden), dtype = \"float32\"),\n",
    "                    name = \"FW3\")\n",
    "FW3.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "FB3 = theano.shared(np.zeros((num_fw3_hidden,), dtype = \"float32\"),\n",
    "                    name = \"FB3\")\n",
    "FB3.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW3, FB3]\n",
    "\n",
    "after_F3 = theano.tensor.maximum(0.0, \n",
    "                                 theano.tensor.dot(after_P2.flatten(2), FW3) + FB3.dimshuffle(\"x\", 0))\n",
    "# print \"after_F3 shape: %s\" % (after_F3.tag.test_value.shape,)\n",
    "\n",
    "\n",
    "num_fw4_hidden = 10\n",
    "FW4 = theano.shared(np.zeros((num_fw3_hidden, num_fw4_hidden), dtype = \"float32\"),\n",
    "                    name = \"FW4\")\n",
    "FW4.tag.initializer = IsotropicGaussian(0.05)\n",
    "\n",
    "FB4 = theano.shared(np.zeros((num_fw4_hidden,), dtype = \"float32\"),\n",
    "                    name = \"FB4\")\n",
    "FB4.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW4, FB4]\n",
    "\n",
    "after_F4 = theano.tensor.dot(after_F3, FW4) + FB4.dimshuffle(\"x\", 0)\n",
    "# print \"after_F4 shape: %s\" % (after_F4.tag.test_value.shape,)\n",
    "\n",
    "log_probs = theano.tensor.nnet.softmax(after_F4)\n",
    "\n",
    "predictions = theano.tensor.argmax(log_probs, axis = 1)\n",
    "\n",
    "error_rate = theano.tensor.neq(predictions, Y.ravel()).mean()\n",
    "nll = -theano.tensor.log(log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()\n",
    "\n",
    "weight_decay = 0.0\n",
    "for p in model_parameters:\n",
    "    if p.name[1] == \"W\":\n",
    "        weight_decay = weight_decay + 1e-3 * (p ** 2).sum()\n",
    "\n",
    "cost = nll + weight_decay\n",
    "\n",
    "# At this point stop computing test values\n",
    "theano.config.compute_test_value = \"off\" # Enable the computation of test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# We have built a computation graph for computing the error_rate, predictions and cost\n",
    "#\n",
    "# svgdotprint(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The updates will update our shared values\n",
    "updates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrate = theano.tensor.scalar(\"lrate\", dtype = \"float32\")\n",
    "momentum = theano.tensor.scalar(\"momentum\", dtype = \"float32\")\n",
    "\n",
    "# Theano will compute the gradients for us\n",
    "gradients = theano.grad(cost, model_parameters)\n",
    "\n",
    "# initialize storage for momentum\n",
    "velocities = [theano.shared(np.zeros_like(p.get_value()), name = \"V_%s\" % (p.name,)) for p in model_parameters]\n",
    "\n",
    "for p, g, v in zip(model_parameters, gradients, velocities):\n",
    "    v_new = momentum * v - lrate * g\n",
    "    p_new = p + v_new\n",
    "    updates += [(v, v_new), (p, p_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(V_CW1, Elemwise{sub,no_inplace}.0),\n",
       " (CW1, Elemwise{add,no_inplace}.0),\n",
       " (V_CB1, Elemwise{sub,no_inplace}.0),\n",
       " (CB1, Elemwise{add,no_inplace}.0),\n",
       " (V_CW2, Elemwise{sub,no_inplace}.0),\n",
       " (CW2, Elemwise{add,no_inplace}.0),\n",
       " (V_CB2, Elemwise{sub,no_inplace}.0),\n",
       " (CB2, Elemwise{add,no_inplace}.0),\n",
       " (V_FW3, Elemwise{sub,no_inplace}.0),\n",
       " (FW3, Elemwise{add,no_inplace}.0),\n",
       " (V_FB3, Elemwise{sub,no_inplace}.0),\n",
       " (FB3, Elemwise{add,no_inplace}.0),\n",
       " (V_FW4, Elemwise{sub,no_inplace}.0),\n",
       " (FW4, Elemwise{add,no_inplace}.0),\n",
       " (V_FB4, Elemwise{sub,no_inplace}.0),\n",
       " (FB4, Elemwise{add,no_inplace}.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compile theano functions\n",
    "\n",
    "# each call to train step will make one SGD step\n",
    "train_step = theano.function([X, Y, lrate, momentum], [cost, error_rate, nll, weight_decay], updates = updates)\n",
    "# each call to predict will return predictions on a batch of data\n",
    "predict = theano.function([X], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(stream):\n",
    "    errs = 0.0\n",
    "    num_samples = 0.0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        errs += (predict(X) != Y.ravel()).sum()\n",
    "        num_samples += Y.shape[0]\n",
    "    return errs / num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utilities to save values of parameters and to load them\n",
    "\n",
    "def init_parameters():\n",
    "    rng = np.random.RandomState(1234)\n",
    "    for p in model_parameters:\n",
    "        p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "\n",
    "def snapshot_parameters():\n",
    "    return [p.get_value(borrow = False) for p in model_parameters]\n",
    "\n",
    "def load_parameters(snapshot):\n",
    "    for p, s in zip(model_parameters, snapshot):\n",
    "        p.set_value(s, borrow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init training\n",
    "\n",
    "i = 0\n",
    "e = 0\n",
    "\n",
    "init_parameters()\n",
    "for v in velocities:\n",
    "    v.set_value(np.zeros_like(v.get_value()))\n",
    "\n",
    "best_valid_error_rate = np.inf\n",
    "best_params = snapshot_parameters()\n",
    "best_params_epoch = 0\n",
    "\n",
    "train_erros = []\n",
    "train_loss = []\n",
    "train_nll = []\n",
    "validation_errors = []\n",
    "\n",
    "number_of_epochs = 3\n",
    "patience_expansion = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At minibatch 100, batch loss 1.110308, batch nll 0.579770, batch error rate 12.000000%\n",
      "At minibatch 200, batch loss 0.770511, batch nll 0.243520, batch error rate 8.000000%\n",
      "At minibatch 300, batch loss 0.611276, batch nll 0.089533, batch error rate 4.000000%\n",
      "At minibatch 400, batch loss 0.815695, batch nll 0.299363, batch error rate 8.000000%\n",
      "At minibatch 500, batch loss 0.574672, batch nll 0.064435, batch error rate 0.000000%\n",
      "At minibatch 600, batch loss 0.757000, batch nll 0.252829, batch error rate 4.000000%\n",
      "At minibatch 700, batch loss 0.536942, batch nll 0.038938, batch error rate 0.000000%\n",
      "At minibatch 800, batch loss 0.523592, batch nll 0.031475, batch error rate 0.000000%\n",
      "At minibatch 900, batch loss 0.549237, batch nll 0.063677, batch error rate 0.000000%\n",
      "At minibatch 1000, batch loss 0.702913, batch nll 0.223101, batch error rate 8.000000%\n",
      "At minibatch 1100, batch loss 0.639446, batch nll 0.166120, batch error rate 12.000000%\n",
      "At minibatch 1200, batch loss 0.485185, batch nll 0.018219, batch error rate 0.000000%\n",
      "At minibatch 1300, batch loss 0.583808, batch nll 0.122344, batch error rate 8.000000%\n",
      "At minibatch 1400, batch loss 0.551804, batch nll 0.096086, batch error rate 4.000000%\n",
      "At minibatch 1500, batch loss 0.494719, batch nll 0.045425, batch error rate 0.000000%\n",
      "At minibatch 1600, batch loss 0.487364, batch nll 0.043927, batch error rate 0.000000%\n",
      "At minibatch 1700, batch loss 0.541322, batch nll 0.103497, batch error rate 4.000000%\n",
      "At minibatch 1800, batch loss 0.448943, batch nll 0.017101, batch error rate 0.000000%\n",
      "At minibatch 1900, batch loss 0.476748, batch nll 0.050718, batch error rate 4.000000%\n",
      "At minibatch 2000, batch loss 0.458183, batch nll 0.038008, batch error rate 0.000000%\n",
      "After epoch 1: valid_err_rate: 2.210000% currently going to do 3 epochs\n",
      "After epoch 1: averaged train_err_rate: 7.290000% averaged train nll: 0.227394 averaged train loss: 0.706648\n",
      "At minibatch 2100, batch loss 0.418278, batch nll 0.003421, batch error rate 0.000000%\n",
      "At minibatch 2200, batch loss 0.424276, batch nll 0.014570, batch error rate 0.000000%\n",
      "At minibatch 2300, batch loss 0.632252, batch nll 0.227441, batch error rate 8.000000%\n",
      "At minibatch 2400, batch loss 0.420264, batch nll 0.020113, batch error rate 0.000000%\n",
      "At minibatch 2500, batch loss 0.398957, batch nll 0.003469, batch error rate 0.000000%\n",
      "At minibatch 2600, batch loss 0.430492, batch nll 0.039320, batch error rate 0.000000%\n",
      "At minibatch 2700, batch loss 0.391869, batch nll 0.004956, batch error rate 0.000000%\n",
      "At minibatch 2800, batch loss 0.399047, batch nll 0.015759, batch error rate 0.000000%\n",
      "At minibatch 2900, batch loss 0.381909, batch nll 0.002280, batch error rate 0.000000%\n",
      "At minibatch 3000, batch loss 0.384738, batch nll 0.008741, batch error rate 0.000000%\n",
      "At minibatch 3100, batch loss 0.411512, batch nll 0.038829, batch error rate 0.000000%\n",
      "At minibatch 3200, batch loss 0.508226, batch nll 0.138942, batch error rate 4.000000%\n",
      "At minibatch 3300, batch loss 0.374101, batch nll 0.007723, batch error rate 0.000000%\n",
      "At minibatch 3400, batch loss 0.402850, batch nll 0.039390, batch error rate 4.000000%\n",
      "At minibatch 3500, batch loss 0.394286, batch nll 0.033718, batch error rate 0.000000%\n",
      "At minibatch 3600, batch loss 0.377106, batch nll 0.019110, batch error rate 0.000000%\n",
      "At minibatch 3700, batch loss 0.359118, batch nll 0.003940, batch error rate 0.000000%\n",
      "At minibatch 3800, batch loss 0.431356, batch nll 0.078868, batch error rate 4.000000%\n",
      "At minibatch 3900, batch loss 0.356206, batch nll 0.006103, batch error rate 0.000000%\n",
      "At minibatch 4000, batch loss 0.354916, batch nll 0.007261, batch error rate 0.000000%\n",
      "After epoch 2: valid_err_rate: 1.340000% currently going to do 4 epochs\n",
      "After epoch 2: averaged train_err_rate: 1.830000% averaged train nll: 0.057570 averaged train loss: 0.436226\n",
      "At minibatch 4100, batch loss 0.348838, batch nll 0.003415, batch error rate 0.000000%\n",
      "At minibatch 4200, batch loss 0.345543, batch nll 0.002338, batch error rate 0.000000%\n",
      "At minibatch 4300, batch loss 0.349356, batch nll 0.008385, batch error rate 0.000000%\n",
      "At minibatch 4400, batch loss 0.347401, batch nll 0.008504, batch error rate 0.000000%\n",
      "At minibatch 4500, batch loss 0.511883, batch nll 0.174984, batch error rate 4.000000%\n",
      "At minibatch 4600, batch loss 0.533488, batch nll 0.198494, batch error rate 4.000000%\n",
      "At minibatch 4700, batch loss 0.360378, batch nll 0.027351, batch error rate 0.000000%\n",
      "At minibatch 4800, batch loss 0.368438, batch nll 0.037294, batch error rate 4.000000%\n",
      "At minibatch 4900, batch loss 0.336208, batch nll 0.006950, batch error rate 0.000000%\n",
      "At minibatch 5000, batch loss 0.431719, batch nll 0.104301, batch error rate 4.000000%\n",
      "At minibatch 5100, batch loss 0.332888, batch nll 0.007221, batch error rate 0.000000%\n",
      "At minibatch 5200, batch loss 0.525870, batch nll 0.201935, batch error rate 4.000000%\n",
      "At minibatch 5300, batch loss 0.348654, batch nll 0.026425, batch error rate 0.000000%\n",
      "At minibatch 5400, batch loss 0.421465, batch nll 0.100923, batch error rate 4.000000%\n",
      "At minibatch 5500, batch loss 0.369602, batch nll 0.050626, batch error rate 0.000000%\n",
      "At minibatch 5600, batch loss 0.339628, batch nll 0.022194, batch error rate 0.000000%\n",
      "At minibatch 5700, batch loss 0.329401, batch nll 0.013478, batch error rate 0.000000%\n",
      "At minibatch 5800, batch loss 0.554994, batch nll 0.240569, batch error rate 8.000000%\n",
      "At minibatch 5900, batch loss 0.372965, batch nll 0.060161, batch error rate 4.000000%\n",
      "At minibatch 6000, batch loss 0.362875, batch nll 0.051493, batch error rate 0.000000%\n",
      "After epoch 3: valid_err_rate: 1.360000% currently going to do 4 epochs\n",
      "After epoch 3: averaged train_err_rate: 1.102000% averaged train nll: 0.036954 averaged train loss: 0.365072\n",
      "At minibatch 6100, batch loss 0.316815, batch nll 0.006798, batch error rate 0.000000%\n",
      "At minibatch 6200, batch loss 0.330881, batch nll 0.022220, batch error rate 0.000000%\n",
      "At minibatch 6300, batch loss 0.322769, batch nll 0.015365, batch error rate 0.000000%\n",
      "At minibatch 6400, batch loss 0.311337, batch nll 0.005258, batch error rate 0.000000%\n",
      "At minibatch 6500, batch loss 0.306489, batch nll 0.001601, batch error rate 0.000000%\n",
      "At minibatch 6600, batch loss 0.309940, batch nll 0.006277, batch error rate 0.000000%\n",
      "At minibatch 6700, batch loss 0.334049, batch nll 0.031611, batch error rate 4.000000%\n",
      "At minibatch 6800, batch loss 0.305111, batch nll 0.003839, batch error rate 0.000000%\n",
      "At minibatch 6900, batch loss 0.439129, batch nll 0.139047, batch error rate 4.000000%\n",
      "At minibatch 7000, batch loss 0.437644, batch nll 0.138738, batch error rate 8.000000%\n",
      "At minibatch 7100, batch loss 0.389682, batch nll 0.091948, batch error rate 4.000000%\n",
      "At minibatch 7200, batch loss 0.328602, batch nll 0.032030, batch error rate 0.000000%\n",
      "At minibatch 7300, batch loss 0.347099, batch nll 0.051617, batch error rate 4.000000%\n",
      "At minibatch 7400, batch loss 0.298876, batch nll 0.004487, batch error rate 0.000000%\n",
      "At minibatch 7500, batch loss 0.527483, batch nll 0.234129, batch error rate 8.000000%\n",
      "At minibatch 7600, batch loss 0.294539, batch nll 0.002187, batch error rate 0.000000%\n",
      "At minibatch 7700, batch loss 0.304086, batch nll 0.012801, batch error rate 0.000000%\n",
      "At minibatch 7800, batch loss 0.511687, batch nll 0.221423, batch error rate 8.000000%\n",
      "At minibatch 7900, batch loss 0.292721, batch nll 0.003384, batch error rate 0.000000%\n",
      "At minibatch 8000, batch loss 0.289980, batch nll 0.001650, batch error rate 0.000000%\n",
      "After epoch 4: valid_err_rate: 1.250000% currently going to do 7 epochs\n",
      "After epoch 4: averaged train_err_rate: 0.936000% averaged train nll: 0.030006 averaged train loss: 0.329198\n",
      "At minibatch 8100, batch loss 0.293669, batch nll 0.006280, batch error rate 0.000000%\n",
      "At minibatch 8200, batch loss 0.316512, batch nll 0.030033, batch error rate 0.000000%\n",
      "At minibatch 8300, batch loss 0.306606, batch nll 0.021055, batch error rate 0.000000%\n",
      "At minibatch 8400, batch loss 0.287497, batch nll 0.002809, batch error rate 0.000000%\n",
      "At minibatch 8500, batch loss 0.492152, batch nll 0.208342, batch error rate 8.000000%\n",
      "At minibatch 8600, batch loss 0.290614, batch nll 0.007676, batch error rate 0.000000%\n",
      "At minibatch 8700, batch loss 0.301822, batch nll 0.019696, batch error rate 0.000000%\n",
      "At minibatch 8800, batch loss 0.320039, batch nll 0.038830, batch error rate 4.000000%\n",
      "At minibatch 8900, batch loss 0.300633, batch nll 0.020199, batch error rate 0.000000%\n",
      "At minibatch 9000, batch loss 0.284706, batch nll 0.005061, batch error rate 0.000000%\n",
      "At minibatch 9100, batch loss 0.297944, batch nll 0.019116, batch error rate 0.000000%\n",
      "At minibatch 9200, batch loss 0.303404, batch nll 0.025387, batch error rate 0.000000%\n",
      "At minibatch 9300, batch loss 0.278191, batch nll 0.000964, batch error rate 0.000000%\n",
      "At minibatch 9400, batch loss 0.279493, batch nll 0.003054, batch error rate 0.000000%\n",
      "At minibatch 9500, batch loss 0.277754, batch nll 0.002087, batch error rate 0.000000%\n",
      "At minibatch 9600, batch loss 0.277775, batch nll 0.002894, batch error rate 0.000000%\n",
      "At minibatch 9700, batch loss 0.349122, batch nll 0.075015, batch error rate 4.000000%\n",
      "At minibatch 9800, batch loss 0.279178, batch nll 0.005827, batch error rate 0.000000%\n",
      "At minibatch 9900, batch loss 0.288805, batch nll 0.016193, batch error rate 0.000000%\n",
      "At minibatch 10000, batch loss 0.282486, batch nll 0.010605, batch error rate 0.000000%\n",
      "After epoch 5: valid_err_rate: 1.160000% currently going to do 8 epochs\n",
      "After epoch 5: averaged train_err_rate: 0.736000% averaged train nll: 0.025996 averaged train loss: 0.305770\n",
      "At minibatch 10100, batch loss 0.304291, batch nll 0.033095, batch error rate 0.000000%\n",
      "At minibatch 10200, batch loss 0.274058, batch nll 0.003561, batch error rate 0.000000%\n",
      "At minibatch 10300, batch loss 0.294442, batch nll 0.024637, batch error rate 0.000000%\n",
      "At minibatch 10400, batch loss 0.299012, batch nll 0.029880, batch error rate 0.000000%\n",
      "At minibatch 10500, batch loss 0.271450, batch nll 0.003003, batch error rate 0.000000%\n",
      "At minibatch 10600, batch loss 0.273848, batch nll 0.006100, batch error rate 0.000000%\n",
      "At minibatch 10700, batch loss 0.305499, batch nll 0.038380, batch error rate 4.000000%\n",
      "At minibatch 10800, batch loss 0.306152, batch nll 0.039651, batch error rate 0.000000%\n",
      "At minibatch 10900, batch loss 0.268111, batch nll 0.002254, batch error rate 0.000000%\n",
      "At minibatch 11000, batch loss 0.440327, batch nll 0.175098, batch error rate 8.000000%\n",
      "At minibatch 11100, batch loss 0.299047, batch nll 0.034445, batch error rate 0.000000%\n",
      "At minibatch 11200, batch loss 0.268849, batch nll 0.004856, batch error rate 0.000000%\n",
      "At minibatch 11300, batch loss 0.266503, batch nll 0.003159, batch error rate 0.000000%\n",
      "At minibatch 11400, batch loss 0.266764, batch nll 0.004033, batch error rate 0.000000%\n",
      "At minibatch 11500, batch loss 0.298916, batch nll 0.036779, batch error rate 0.000000%\n",
      "At minibatch 11600, batch loss 0.267835, batch nll 0.006307, batch error rate 0.000000%\n",
      "At minibatch 11700, batch loss 0.290035, batch nll 0.029103, batch error rate 0.000000%\n",
      "At minibatch 11800, batch loss 0.265782, batch nll 0.005426, batch error rate 0.000000%\n",
      "At minibatch 11900, batch loss 0.287925, batch nll 0.028153, batch error rate 0.000000%\n",
      "At minibatch 12000, batch loss 0.384114, batch nll 0.124942, batch error rate 4.000000%\n",
      "After epoch 6: valid_err_rate: 1.210000% currently going to do 8 epochs\n",
      "After epoch 6: averaged train_err_rate: 0.648000% averaged train nll: 0.023788 averaged train loss: 0.289106\n",
      "At minibatch 12100, batch loss 0.263806, batch nll 0.005184, batch error rate 0.000000%\n",
      "At minibatch 12200, batch loss 0.261991, batch nll 0.003900, batch error rate 0.000000%\n",
      "At minibatch 12300, batch loss 0.269358, batch nll 0.011830, batch error rate 0.000000%\n",
      "At minibatch 12400, batch loss 0.260357, batch nll 0.003350, batch error rate 0.000000%\n",
      "At minibatch 12500, batch loss 0.261006, batch nll 0.004550, batch error rate 0.000000%\n",
      "At minibatch 12600, batch loss 0.278132, batch nll 0.022171, batch error rate 0.000000%\n",
      "At minibatch 12700, batch loss 0.257324, batch nll 0.001880, batch error rate 0.000000%\n",
      "At minibatch 12800, batch loss 0.258840, batch nll 0.003908, batch error rate 0.000000%\n",
      "At minibatch 12900, batch loss 0.268397, batch nll 0.013962, batch error rate 0.000000%\n",
      "At minibatch 13000, batch loss 0.265117, batch nll 0.011182, batch error rate 0.000000%\n",
      "At minibatch 13100, batch loss 0.293264, batch nll 0.039835, batch error rate 0.000000%\n",
      "At minibatch 13200, batch loss 0.260124, batch nll 0.007209, batch error rate 0.000000%\n",
      "At minibatch 13300, batch loss 0.285723, batch nll 0.033298, batch error rate 0.000000%\n",
      "At minibatch 13400, batch loss 0.292996, batch nll 0.041067, batch error rate 4.000000%\n",
      "At minibatch 13500, batch loss 0.282386, batch nll 0.030936, batch error rate 0.000000%\n",
      "At minibatch 13600, batch loss 0.262854, batch nll 0.011891, batch error rate 0.000000%\n",
      "At minibatch 13700, batch loss 0.271419, batch nll 0.020966, batch error rate 0.000000%\n",
      "At minibatch 13800, batch loss 0.280721, batch nll 0.030751, batch error rate 0.000000%\n",
      "At minibatch 13900, batch loss 0.300722, batch nll 0.051222, batch error rate 4.000000%\n",
      "At minibatch 14000, batch loss 0.278346, batch nll 0.029299, batch error rate 0.000000%\n",
      "After epoch 7: valid_err_rate: 1.100000% currently going to do 11 epochs\n",
      "After epoch 7: averaged train_err_rate: 0.620000% averaged train nll: 0.022245 averaged train loss: 0.276221\n",
      "At minibatch 14100, batch loss 0.316620, batch nll 0.068020, batch error rate 4.000000%\n",
      "At minibatch 14200, batch loss 0.251192, batch nll 0.003037, batch error rate 0.000000%\n",
      "At minibatch 14300, batch loss 0.257923, batch nll 0.010214, batch error rate 0.000000%\n",
      "At minibatch 14400, batch loss 0.253842, batch nll 0.006575, batch error rate 0.000000%\n",
      "At minibatch 14500, batch loss 0.253177, batch nll 0.006345, batch error rate 0.000000%\n",
      "At minibatch 14600, batch loss 0.250167, batch nll 0.003753, batch error rate 0.000000%\n",
      "At minibatch 14700, batch loss 0.252962, batch nll 0.006981, batch error rate 0.000000%\n",
      "At minibatch 14800, batch loss 0.303968, batch nll 0.058440, batch error rate 4.000000%\n",
      "At minibatch 14900, batch loss 0.251141, batch nll 0.006036, batch error rate 0.000000%\n",
      "At minibatch 15000, batch loss 0.251361, batch nll 0.006686, batch error rate 0.000000%\n",
      "At minibatch 15100, batch loss 0.253307, batch nll 0.009046, batch error rate 0.000000%\n",
      "At minibatch 15200, batch loss 0.275525, batch nll 0.031666, batch error rate 0.000000%\n",
      "At minibatch 15300, batch loss 0.261581, batch nll 0.018133, batch error rate 0.000000%\n",
      "At minibatch 15400, batch loss 0.277615, batch nll 0.034572, batch error rate 0.000000%\n",
      "At minibatch 15500, batch loss 0.258462, batch nll 0.015824, batch error rate 0.000000%\n",
      "At minibatch 15600, batch loss 0.260861, batch nll 0.018626, batch error rate 0.000000%\n",
      "At minibatch 15700, batch loss 0.244865, batch nll 0.003024, batch error rate 0.000000%\n",
      "At minibatch 15800, batch loss 0.242208, batch nll 0.000735, batch error rate 0.000000%\n",
      "At minibatch 15900, batch loss 0.275938, batch nll 0.034852, batch error rate 0.000000%\n",
      "At minibatch 16000, batch loss 0.266889, batch nll 0.026206, batch error rate 0.000000%\n",
      "After epoch 8: valid_err_rate: 1.210000% currently going to do 11 epochs\n",
      "After epoch 8: averaged train_err_rate: 0.532000% averaged train nll: 0.021170 averaged train loss: 0.265918\n",
      "At minibatch 16100, batch loss 0.247648, batch nll 0.007349, batch error rate 0.000000%\n",
      "At minibatch 16200, batch loss 0.257630, batch nll 0.017693, batch error rate 0.000000%\n",
      "At minibatch 16300, batch loss 0.243184, batch nll 0.003624, batch error rate 0.000000%\n",
      "At minibatch 16400, batch loss 0.242751, batch nll 0.003575, batch error rate 0.000000%\n",
      "At minibatch 16500, batch loss 0.257096, batch nll 0.018291, batch error rate 0.000000%\n",
      "At minibatch 16600, batch loss 0.243933, batch nll 0.005473, batch error rate 0.000000%\n",
      "At minibatch 16700, batch loss 0.238509, batch nll 0.000424, batch error rate 0.000000%\n",
      "At minibatch 16800, batch loss 0.251797, batch nll 0.014047, batch error rate 0.000000%\n",
      "At minibatch 16900, batch loss 0.238835, batch nll 0.001462, batch error rate 0.000000%\n",
      "At minibatch 17000, batch loss 0.247098, batch nll 0.010080, batch error rate 0.000000%\n",
      "At minibatch 17100, batch loss 0.262896, batch nll 0.026228, batch error rate 0.000000%\n",
      "At minibatch 17200, batch loss 0.238377, batch nll 0.002052, batch error rate 0.000000%\n",
      "At minibatch 17300, batch loss 0.243503, batch nll 0.007557, batch error rate 0.000000%\n",
      "At minibatch 17400, batch loss 0.238148, batch nll 0.002540, batch error rate 0.000000%\n",
      "At minibatch 17500, batch loss 0.246702, batch nll 0.011439, batch error rate 0.000000%\n",
      "At minibatch 17600, batch loss 0.258744, batch nll 0.023813, batch error rate 0.000000%\n",
      "At minibatch 17700, batch loss 0.257583, batch nll 0.022993, batch error rate 0.000000%\n",
      "At minibatch 17800, batch loss 0.238250, batch nll 0.003993, batch error rate 0.000000%\n",
      "At minibatch 17900, batch loss 0.249667, batch nll 0.015725, batch error rate 0.000000%\n",
      "At minibatch 18000, batch loss 0.274782, batch nll 0.041164, batch error rate 4.000000%\n",
      "After epoch 9: valid_err_rate: 1.100000% currently going to do 11 epochs\n",
      "After epoch 9: averaged train_err_rate: 0.528000% averaged train nll: 0.019946 averaged train loss: 0.257000\n",
      "At minibatch 18100, batch loss 0.246123, batch nll 0.012837, batch error rate 0.000000%\n",
      "At minibatch 18200, batch loss 0.242170, batch nll 0.009184, batch error rate 0.000000%\n",
      "At minibatch 18300, batch loss 0.235000, batch nll 0.002339, batch error rate 0.000000%\n",
      "At minibatch 18400, batch loss 0.245017, batch nll 0.012688, batch error rate 0.000000%\n",
      "At minibatch 18500, batch loss 0.245337, batch nll 0.013324, batch error rate 0.000000%\n",
      "At minibatch 18600, batch loss 0.235339, batch nll 0.003645, batch error rate 0.000000%\n",
      "At minibatch 18700, batch loss 0.233138, batch nll 0.001766, batch error rate 0.000000%\n",
      "At minibatch 18800, batch loss 0.244152, batch nll 0.013073, batch error rate 0.000000%\n",
      "At minibatch 18900, batch loss 0.259183, batch nll 0.028406, batch error rate 0.000000%\n",
      "At minibatch 19000, batch loss 0.242608, batch nll 0.012133, batch error rate 0.000000%\n",
      "At minibatch 19100, batch loss 0.246288, batch nll 0.016106, batch error rate 0.000000%\n",
      "At minibatch 19200, batch loss 0.241509, batch nll 0.011619, batch error rate 0.000000%\n",
      "At minibatch 19300, batch loss 0.234214, batch nll 0.004612, batch error rate 0.000000%\n",
      "At minibatch 19400, batch loss 0.235151, batch nll 0.005850, batch error rate 0.000000%\n",
      "At minibatch 19500, batch loss 0.233878, batch nll 0.004882, batch error rate 0.000000%\n",
      "At minibatch 19600, batch loss 0.236977, batch nll 0.008282, batch error rate 0.000000%\n",
      "At minibatch 19700, batch loss 0.233366, batch nll 0.004972, batch error rate 0.000000%\n",
      "At minibatch 19800, batch loss 0.229161, batch nll 0.001082, batch error rate 0.000000%\n",
      "At minibatch 19900, batch loss 0.230627, batch nll 0.002834, batch error rate 0.000000%\n",
      "At minibatch 20000, batch loss 0.256254, batch nll 0.028752, batch error rate 0.000000%\n",
      "After epoch 10: valid_err_rate: 1.040000% currently going to do 16 epochs\n",
      "After epoch 10: averaged train_err_rate: 0.452000% averaged train nll: 0.019311 averaged train loss: 0.249817\n",
      "At minibatch 20100, batch loss 0.237028, batch nll 0.009782, batch error rate 0.000000%\n",
      "At minibatch 20200, batch loss 0.235704, batch nll 0.008737, batch error rate 0.000000%\n",
      "At minibatch 20300, batch loss 0.253339, batch nll 0.026645, batch error rate 0.000000%\n",
      "At minibatch 20400, batch loss 0.315862, batch nll 0.089454, batch error rate 4.000000%\n",
      "At minibatch 20500, batch loss 0.235218, batch nll 0.009083, batch error rate 0.000000%\n",
      "At minibatch 20600, batch loss 0.278869, batch nll 0.053009, batch error rate 4.000000%\n",
      "At minibatch 20700, batch loss 0.227632, batch nll 0.002070, batch error rate 0.000000%\n",
      "At minibatch 20800, batch loss 0.258326, batch nll 0.033041, batch error rate 0.000000%\n",
      "At minibatch 20900, batch loss 0.302309, batch nll 0.077295, batch error rate 4.000000%\n",
      "At minibatch 21000, batch loss 0.228336, batch nll 0.003592, batch error rate 0.000000%\n",
      "At minibatch 21100, batch loss 0.243873, batch nll 0.019398, batch error rate 0.000000%\n",
      "At minibatch 21200, batch loss 0.229567, batch nll 0.005355, batch error rate 0.000000%\n",
      "At minibatch 21300, batch loss 0.228734, batch nll 0.004778, batch error rate 0.000000%\n",
      "At minibatch 21400, batch loss 0.228483, batch nll 0.004788, batch error rate 0.000000%\n",
      "At minibatch 21500, batch loss 0.231654, batch nll 0.008221, batch error rate 0.000000%\n",
      "At minibatch 21600, batch loss 0.320612, batch nll 0.097413, batch error rate 4.000000%\n",
      "At minibatch 21700, batch loss 0.247219, batch nll 0.024283, batch error rate 0.000000%\n",
      "At minibatch 21800, batch loss 0.284241, batch nll 0.061555, batch error rate 4.000000%\n",
      "At minibatch 21900, batch loss 0.226512, batch nll 0.004081, batch error rate 0.000000%\n",
      "At minibatch 22000, batch loss 0.228651, batch nll 0.006480, batch error rate 0.000000%\n",
      "After epoch 11: valid_err_rate: 0.990000% currently going to do 17 epochs\n",
      "After epoch 11: averaged train_err_rate: 0.444000% averaged train nll: 0.018682 averaged train loss: 0.243468\n",
      "At minibatch 22100, batch loss 0.225410, batch nll 0.003485, batch error rate 0.000000%\n",
      "At minibatch 22200, batch loss 0.224335, batch nll 0.002663, batch error rate 0.000000%\n",
      "At minibatch 22300, batch loss 0.246063, batch nll 0.024618, batch error rate 0.000000%\n",
      "At minibatch 22400, batch loss 0.242585, batch nll 0.021387, batch error rate 0.000000%\n",
      "At minibatch 22500, batch loss 0.221741, batch nll 0.000790, batch error rate 0.000000%\n",
      "At minibatch 22600, batch loss 0.229544, batch nll 0.008846, batch error rate 0.000000%\n",
      "At minibatch 22700, batch loss 0.222504, batch nll 0.002055, batch error rate 0.000000%\n",
      "At minibatch 22800, batch loss 0.231578, batch nll 0.011383, batch error rate 0.000000%\n",
      "At minibatch 22900, batch loss 0.223017, batch nll 0.003054, batch error rate 0.000000%\n",
      "At minibatch 23000, batch loss 0.236169, batch nll 0.016434, batch error rate 0.000000%\n",
      "At minibatch 23100, batch loss 0.219984, batch nll 0.000481, batch error rate 0.000000%\n",
      "At minibatch 23200, batch loss 0.226201, batch nll 0.006931, batch error rate 0.000000%\n",
      "At minibatch 23300, batch loss 0.260634, batch nll 0.041592, batch error rate 0.000000%\n",
      "At minibatch 23400, batch loss 0.221408, batch nll 0.002599, batch error rate 0.000000%\n",
      "At minibatch 23500, batch loss 0.234439, batch nll 0.015871, batch error rate 0.000000%\n",
      "At minibatch 23600, batch loss 0.219397, batch nll 0.001061, batch error rate 0.000000%\n",
      "At minibatch 23700, batch loss 0.223478, batch nll 0.005368, batch error rate 0.000000%\n",
      "At minibatch 23800, batch loss 0.224360, batch nll 0.006475, batch error rate 0.000000%\n",
      "At minibatch 23900, batch loss 0.234793, batch nll 0.017132, batch error rate 0.000000%\n",
      "At minibatch 24000, batch loss 0.233088, batch nll 0.015661, batch error rate 0.000000%\n",
      "After epoch 12: valid_err_rate: 1.050000% currently going to do 17 epochs\n",
      "After epoch 12: averaged train_err_rate: 0.452000% averaged train nll: 0.018177 averaged train loss: 0.237937\n",
      "At minibatch 24100, batch loss 0.250537, batch nll 0.033327, batch error rate 0.000000%\n",
      "At minibatch 24200, batch loss 0.226108, batch nll 0.009127, batch error rate 0.000000%\n",
      "At minibatch 24300, batch loss 0.247865, batch nll 0.031100, batch error rate 0.000000%\n",
      "At minibatch 24400, batch loss 0.285775, batch nll 0.069225, batch error rate 4.000000%\n",
      "At minibatch 24500, batch loss 0.218826, batch nll 0.002488, batch error rate 0.000000%\n",
      "At minibatch 24600, batch loss 0.218177, batch nll 0.002061, batch error rate 0.000000%\n",
      "At minibatch 24700, batch loss 0.238585, batch nll 0.022686, batch error rate 0.000000%\n",
      "At minibatch 24800, batch loss 0.226260, batch nll 0.010578, batch error rate 0.000000%\n",
      "At minibatch 24900, batch loss 0.217912, batch nll 0.002440, batch error rate 0.000000%\n",
      "At minibatch 25000, batch loss 0.232012, batch nll 0.016753, batch error rate 0.000000%\n",
      "At minibatch 25100, batch loss 0.217731, batch nll 0.002695, batch error rate 0.000000%\n",
      "At minibatch 25200, batch loss 0.220206, batch nll 0.005393, batch error rate 0.000000%\n",
      "At minibatch 25300, batch loss 0.215630, batch nll 0.001035, batch error rate 0.000000%\n",
      "At minibatch 25400, batch loss 0.233922, batch nll 0.019521, batch error rate 0.000000%\n",
      "At minibatch 25500, batch loss 0.215149, batch nll 0.000940, batch error rate 0.000000%\n",
      "At minibatch 25600, batch loss 0.284378, batch nll 0.070378, batch error rate 4.000000%\n",
      "At minibatch 25700, batch loss 0.216957, batch nll 0.003162, batch error rate 0.000000%\n",
      "At minibatch 25800, batch loss 0.224970, batch nll 0.011384, batch error rate 0.000000%\n",
      "At minibatch 25900, batch loss 0.215493, batch nll 0.002114, batch error rate 0.000000%\n",
      "At minibatch 26000, batch loss 0.368608, batch nll 0.155433, batch error rate 4.000000%\n",
      "After epoch 13: valid_err_rate: 1.030000% currently going to do 17 epochs\n",
      "After epoch 13: averaged train_err_rate: 0.412000% averaged train nll: 0.017756 averaged train loss: 0.233024\n",
      "At minibatch 26100, batch loss 0.225373, batch nll 0.012398, batch error rate 0.000000%\n",
      "At minibatch 26200, batch loss 0.249337, batch nll 0.036566, batch error rate 0.000000%\n",
      "At minibatch 26300, batch loss 0.224587, batch nll 0.012029, batch error rate 0.000000%\n",
      "At minibatch 26400, batch loss 0.213800, batch nll 0.001432, batch error rate 0.000000%\n",
      "At minibatch 26500, batch loss 0.221624, batch nll 0.009461, batch error rate 0.000000%\n",
      "At minibatch 26600, batch loss 0.237127, batch nll 0.025173, batch error rate 0.000000%\n",
      "At minibatch 26700, batch loss 0.252652, batch nll 0.040881, batch error rate 4.000000%\n",
      "At minibatch 26800, batch loss 0.221077, batch nll 0.009491, batch error rate 0.000000%\n",
      "At minibatch 26900, batch loss 0.216527, batch nll 0.005130, batch error rate 0.000000%\n",
      "At minibatch 27000, batch loss 0.213737, batch nll 0.002532, batch error rate 0.000000%\n",
      "At minibatch 27100, batch loss 0.219910, batch nll 0.008908, batch error rate 0.000000%\n",
      "At minibatch 27200, batch loss 0.219926, batch nll 0.009091, batch error rate 0.000000%\n",
      "At minibatch 27300, batch loss 0.213975, batch nll 0.003324, batch error rate 0.000000%\n",
      "At minibatch 27400, batch loss 0.227969, batch nll 0.017512, batch error rate 0.000000%\n",
      "At minibatch 27500, batch loss 0.215339, batch nll 0.005064, batch error rate 0.000000%\n",
      "At minibatch 27600, batch loss 0.346410, batch nll 0.136323, batch error rate 4.000000%\n",
      "At minibatch 27700, batch loss 0.225902, batch nll 0.016001, batch error rate 0.000000%\n",
      "At minibatch 27800, batch loss 0.223791, batch nll 0.014074, batch error rate 0.000000%\n",
      "At minibatch 27900, batch loss 0.241306, batch nll 0.031771, batch error rate 0.000000%\n",
      "At minibatch 28000, batch loss 0.212905, batch nll 0.003558, batch error rate 0.000000%\n",
      "After epoch 14: valid_err_rate: 1.060000% currently going to do 17 epochs\n",
      "After epoch 14: averaged train_err_rate: 0.366000% averaged train nll: 0.017420 averaged train loss: 0.228641\n",
      "At minibatch 28100, batch loss 0.212937, batch nll 0.003782, batch error rate 0.000000%\n",
      "At minibatch 28200, batch loss 0.216377, batch nll 0.007396, batch error rate 0.000000%\n",
      "At minibatch 28300, batch loss 0.219421, batch nll 0.010623, batch error rate 0.000000%\n",
      "At minibatch 28400, batch loss 0.221285, batch nll 0.012663, batch error rate 0.000000%\n",
      "At minibatch 28500, batch loss 0.222321, batch nll 0.013871, batch error rate 0.000000%\n",
      "At minibatch 28600, batch loss 0.212172, batch nll 0.003898, batch error rate 0.000000%\n",
      "At minibatch 28700, batch loss 0.209785, batch nll 0.001697, batch error rate 0.000000%\n",
      "At minibatch 28800, batch loss 0.211186, batch nll 0.003280, batch error rate 0.000000%\n",
      "At minibatch 28900, batch loss 0.210569, batch nll 0.002838, batch error rate 0.000000%\n",
      "At minibatch 29000, batch loss 0.265909, batch nll 0.058362, batch error rate 0.000000%\n",
      "At minibatch 29100, batch loss 0.218081, batch nll 0.010718, batch error rate 0.000000%\n",
      "At minibatch 29200, batch loss 0.211442, batch nll 0.004253, batch error rate 0.000000%\n",
      "At minibatch 29300, batch loss 0.220950, batch nll 0.013933, batch error rate 0.000000%\n",
      "At minibatch 29400, batch loss 0.214150, batch nll 0.007300, batch error rate 0.000000%\n",
      "At minibatch 29500, batch loss 0.217481, batch nll 0.010796, batch error rate 0.000000%\n",
      "At minibatch 29600, batch loss 0.212252, batch nll 0.005740, batch error rate 0.000000%\n",
      "At minibatch 29700, batch loss 0.208169, batch nll 0.001814, batch error rate 0.000000%\n",
      "At minibatch 29800, batch loss 0.207701, batch nll 0.001514, batch error rate 0.000000%\n",
      "At minibatch 29900, batch loss 0.235769, batch nll 0.029744, batch error rate 0.000000%\n",
      "At minibatch 30000, batch loss 0.207122, batch nll 0.001262, batch error rate 0.000000%\n",
      "After epoch 15: valid_err_rate: 1.010000% currently going to do 17 epochs\n",
      "After epoch 15: averaged train_err_rate: 0.388000% averaged train nll: 0.017052 averaged train loss: 0.224619\n",
      "At minibatch 30100, batch loss 0.371574, batch nll 0.165882, batch error rate 4.000000%\n",
      "At minibatch 30200, batch loss 0.209412, batch nll 0.003888, batch error rate 0.000000%\n",
      "At minibatch 30300, batch loss 0.210434, batch nll 0.005074, batch error rate 0.000000%\n",
      "At minibatch 30400, batch loss 0.235767, batch nll 0.030566, batch error rate 0.000000%\n",
      "At minibatch 30500, batch loss 0.218573, batch nll 0.013535, batch error rate 0.000000%\n",
      "At minibatch 30600, batch loss 0.211154, batch nll 0.006279, batch error rate 0.000000%\n",
      "At minibatch 30700, batch loss 0.209328, batch nll 0.004614, batch error rate 0.000000%\n",
      "At minibatch 30800, batch loss 0.207587, batch nll 0.003049, batch error rate 0.000000%\n",
      "At minibatch 30900, batch loss 0.208737, batch nll 0.004365, batch error rate 0.000000%\n",
      "At minibatch 31000, batch loss 0.256690, batch nll 0.052476, batch error rate 4.000000%\n",
      "At minibatch 31100, batch loss 0.211668, batch nll 0.007612, batch error rate 0.000000%\n",
      "At minibatch 31200, batch loss 0.221806, batch nll 0.017905, batch error rate 0.000000%\n",
      "At minibatch 31300, batch loss 0.215352, batch nll 0.011606, batch error rate 0.000000%\n",
      "At minibatch 31400, batch loss 0.206133, batch nll 0.002548, batch error rate 0.000000%\n",
      "At minibatch 31500, batch loss 0.226029, batch nll 0.022597, batch error rate 0.000000%\n",
      "At minibatch 31600, batch loss 0.204167, batch nll 0.000893, batch error rate 0.000000%\n",
      "At minibatch 31700, batch loss 0.205496, batch nll 0.002374, batch error rate 0.000000%\n",
      "At minibatch 31800, batch loss 0.204274, batch nll 0.001303, batch error rate 0.000000%\n",
      "At minibatch 31900, batch loss 0.221735, batch nll 0.018919, batch error rate 0.000000%\n",
      "At minibatch 32000, batch loss 0.214049, batch nll 0.011382, batch error rate 0.000000%\n",
      "After epoch 16: valid_err_rate: 1.090000% currently going to do 17 epochs\n",
      "After epoch 16: averaged train_err_rate: 0.388000% averaged train nll: 0.016950 averaged train loss: 0.221184\n",
      "At minibatch 32100, batch loss 0.222938, batch nll 0.020423, batch error rate 0.000000%\n",
      "At minibatch 32200, batch loss 0.208237, batch nll 0.005874, batch error rate 0.000000%\n",
      "At minibatch 32300, batch loss 0.208801, batch nll 0.006595, batch error rate 0.000000%\n",
      "At minibatch 32400, batch loss 0.212093, batch nll 0.010055, batch error rate 0.000000%\n",
      "At minibatch 32500, batch loss 0.236029, batch nll 0.034137, batch error rate 0.000000%\n",
      "At minibatch 32600, batch loss 0.228897, batch nll 0.027153, batch error rate 0.000000%\n",
      "At minibatch 32700, batch loss 0.202466, batch nll 0.000863, batch error rate 0.000000%\n",
      "At minibatch 32800, batch loss 0.206069, batch nll 0.004616, batch error rate 0.000000%\n",
      "At minibatch 32900, batch loss 0.247299, batch nll 0.046003, batch error rate 0.000000%\n",
      "At minibatch 33000, batch loss 0.207455, batch nll 0.006299, batch error rate 0.000000%\n",
      "At minibatch 33100, batch loss 0.258594, batch nll 0.057587, batch error rate 4.000000%\n",
      "At minibatch 33200, batch loss 0.241771, batch nll 0.040907, batch error rate 0.000000%\n",
      "At minibatch 33300, batch loss 0.206814, batch nll 0.006096, batch error rate 0.000000%\n",
      "At minibatch 33400, batch loss 0.242124, batch nll 0.041549, batch error rate 0.000000%\n",
      "At minibatch 33500, batch loss 0.228998, batch nll 0.028568, batch error rate 0.000000%\n",
      "At minibatch 33600, batch loss 0.207053, batch nll 0.006759, batch error rate 0.000000%\n",
      "At minibatch 33700, batch loss 0.200436, batch nll 0.000283, batch error rate 0.000000%\n",
      "At minibatch 33800, batch loss 0.209896, batch nll 0.009887, batch error rate 0.000000%\n",
      "At minibatch 33900, batch loss 0.202579, batch nll 0.002709, batch error rate 0.000000%\n",
      "At minibatch 34000, batch loss 0.202615, batch nll 0.002886, batch error rate 0.000000%\n",
      "After epoch 17: valid_err_rate: 1.010000% currently going to do 17 epochs\n",
      "After epoch 17: averaged train_err_rate: 0.382000% averaged train nll: 0.016648 averaged train loss: 0.217816\n",
      "At minibatch 34100, batch loss 0.200950, batch nll 0.001360, batch error rate 0.000000%\n",
      "At minibatch 34200, batch loss 0.246539, batch nll 0.047089, batch error rate 4.000000%\n",
      "At minibatch 34300, batch loss 0.199565, batch nll 0.000256, batch error rate 0.000000%\n",
      "At minibatch 34400, batch loss 0.204026, batch nll 0.004863, batch error rate 0.000000%\n",
      "At minibatch 34500, batch loss 0.289285, batch nll 0.090258, batch error rate 4.000000%\n",
      "At minibatch 34600, batch loss 0.207021, batch nll 0.008129, batch error rate 0.000000%\n",
      "At minibatch 34700, batch loss 0.240304, batch nll 0.041546, batch error rate 4.000000%\n",
      "At minibatch 34800, batch loss 0.203667, batch nll 0.005047, batch error rate 0.000000%\n",
      "At minibatch 34900, batch loss 0.211637, batch nll 0.013152, batch error rate 0.000000%\n",
      "At minibatch 35000, batch loss 0.245937, batch nll 0.047590, batch error rate 4.000000%\n",
      "At minibatch 35100, batch loss 0.203131, batch nll 0.004919, batch error rate 0.000000%\n",
      "At minibatch 35200, batch loss 0.226402, batch nll 0.028332, batch error rate 0.000000%\n",
      "At minibatch 35300, batch loss 0.202538, batch nll 0.004593, batch error rate 0.000000%\n",
      "At minibatch 35400, batch loss 0.202291, batch nll 0.004487, batch error rate 0.000000%\n",
      "At minibatch 35500, batch loss 0.199601, batch nll 0.001934, batch error rate 0.000000%\n",
      "At minibatch 35600, batch loss 0.199505, batch nll 0.001975, batch error rate 0.000000%\n",
      "At minibatch 35700, batch loss 0.209682, batch nll 0.012281, batch error rate 0.000000%\n",
      "At minibatch 35800, batch loss 0.209676, batch nll 0.012406, batch error rate 0.000000%\n",
      "At minibatch 35900, batch loss 0.282960, batch nll 0.085826, batch error rate 4.000000%\n",
      "At minibatch 36000, batch loss 0.203831, batch nll 0.006827, batch error rate 0.000000%\n",
      "After epoch 18: valid_err_rate: 1.060000% currently going to do 17 epochs\n",
      "After epoch 18: averaged train_err_rate: 0.370000% averaged train nll: 0.016317 averaged train loss: 0.214668\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "while e < number_of_epochs: # This loop goes over epochs\n",
    "    e += 1\n",
    "    # First train on all data from this batch\n",
    "    epoch_start_i = i\n",
    "    for X_batch, Y_batch in mnist_train_stream.get_epoch_iterator(): \n",
    "        i += 1\n",
    "        \n",
    "        K = 2000\n",
    "        lrate = 4e-3 * K / np.maximum(K, i)\n",
    "        momentum = 0.9\n",
    "        \n",
    "        L, err_rate, nll, wdec = train_step(X_batch, Y_batch, lrate, momentum)\n",
    "        \n",
    "        # print [p.get_value().ravel()[: 10] for p in model_parameters]\n",
    "        # print [p.get_value().ravel()[: 10] for p in velocities]\n",
    "        \n",
    "        train_loss.append((i, L))\n",
    "        train_erros.append((i, err_rate))\n",
    "        train_nll.append((i, nll))\n",
    "        if i % 100 == 0:\n",
    "            print \"At minibatch %d, batch loss %f, batch nll %f, batch error rate %f%%\" % (i, L, nll, err_rate * 100)\n",
    "        \n",
    "    # After an epoch compute validation error\n",
    "    val_error_rate = compute_error_rate(mnist_validation_stream)\n",
    "    if val_error_rate < best_valid_error_rate:\n",
    "        number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion + 1)\n",
    "        best_valid_error_rate = val_error_rate\n",
    "        best_params = snapshot_parameters()\n",
    "        best_params_epoch = e\n",
    "    validation_errors.append((i, val_error_rate))\n",
    "    print \"After epoch %d: valid_err_rate: %f%% currently going to do %d epochs\" \\\n",
    "          % (e, val_error_rate * 100, number_of_epochs)\n",
    "    print \"After epoch %d: averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" \\\n",
    "          % (e,\n",
    "             np.mean(np.asarray(train_erros)[epoch_start_i :, 1]) * 100, \n",
    "             np.mean(np.asarray(train_nll)[epoch_start_i :, 1]),\n",
    "             np.mean(np.asarray(train_loss)[epoch_start_i :, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting network parameters from after epoch 11\n",
      "Test error rate is 0.980000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7467a4a790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEDCAYAAADayhiNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5P8B/TXs8dRzhFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f748332e450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"Setting network parameters from after epoch %d\" % (best_params_epoch)\n",
    "load_parameters(best_params)\n",
    "\n",
    "print \"Test error rate is %f%%\" % (compute_error_rate(mnist_test_stream) * 100.0,)\n",
    "\n",
    "subplot(2, 1, 1)\n",
    "train_nll_a = np.array(train_nll)\n",
    "semilogy(train_nll_a[:, 0], train_nll_a[:, 1], label = \"batch train nll\")\n",
    "legend()\n",
    "\n",
    "subplot(2, 1, 2)\n",
    "train_erros_a = np.array(train_erros)\n",
    "plot(train_erros_a[:, 0], train_erros_a[:, 1], label = \"batch train error rate\")\n",
    "validation_errors_a = np.array(validation_errors)\n",
    "plot(validation_errors_a[:, 0], validation_errors_a[:, 1], label = \"validation error rate\", color = \"r\")\n",
    "ylim(0, 0.2)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAACWCAYAAAD64bJyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbIAi/gVgspZseso61AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74741eac50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How do the filters in the first layer look like?\n",
    "\n",
    "plot_mat(CW1.get_value(), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iii = predict.maker.inputs[0]\n",
    "X = iii.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a function that shows how the network processes an image\n",
    "middle_layers_computer = theano.function([X], [X,\n",
    "                                               after_C1,\n",
    "                                               after_P1,\n",
    "                                               after_C2,\n",
    "                                               after_P2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAEKCAYAAAA2FzjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neAjyb2PouEvHlHWZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74663bd910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAACuCAYAAAASyDeyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74665eb8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAACrCAYAAABCBaYBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7466f0f2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAADmCAYAAADxw7+zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7466428fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAADjCAYAAAChDi4AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnCCwAcAJAhsAnCCwAcAJAhsAnPgvyJEPU1JU85MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f746652f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num = 5\n",
    "middle_layers = middle_layers_computer(X_test_value[img_num : img_num + 1])\n",
    "\n",
    "for ml, name in zip(middle_layers, [\"X\", \"C1\", \"P1\", \"C2\", \"P2\"]):\n",
    "    plot_mat(ml.transpose(1, 0, 2, 3), cmap = \"gray\")\n",
    "    title(name)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
